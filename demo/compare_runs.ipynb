{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pycolmap\n",
    "from pathlib import Path\n",
    "\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from hloc.utils.io import list_h5_names, get_matches\n",
    "\n",
    "from pixhloc.utils.eval import eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = \"../image-matching-challenge-2023\"\n",
    "MODE = \"train\"\n",
    "\n",
    "datasets = {\n",
    "    \"heritage\": [\"cyprus\", \"dioscuri\", \"wall\"],\n",
    "    \"haiper\": [\"bike\", \"chairs\", \"fountain\"],\n",
    "    \"urban\": [\"kyiv-puppet-theater\"],\n",
    "}\n",
    "\n",
    "out_dir = Path(\"../outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = os.listdir(out_dir)\n",
    "runs = [r for r in runs if not r.startswith(\".\")]\n",
    "runs = sorted(runs)\n",
    "\n",
    "# fil = [\"disk\", 'loftr', 'ensemble'] + [\"1600px\"]\n",
    "\n",
    "# runs = [r for r in runs if all(f not in r for f in fil)]\n",
    "\n",
    "fil_runs = [\n",
    "    # \"ALIKED-rot-pixsfm-sci\",\n",
    "    # \"ALIKED+DISK-rotwrap-pixsfm-sci\",\n",
    "    # \"ALIKED+SIFT+SPv2-rot-pixsfm-sci\",\n",
    "    # \"ALIKED+SPv2-rot-pixsfm-sci\",\n",
    "    # \"DISK+LG+sift+NN-rot-pixsfm-sci\",\n",
    "    # \"DISK+SIFT+SPv2-rot-pixsfm-sci\",\n",
    "    # \"DISK+SPv2+LG-rot-pixsfm-sci\",\n",
    "    # \"DISK+SPv2-rot-pixsfm-sci\",\n",
    "    # \"SP+LG+sift+NN-rot-pixsfm-sci\",\n",
    "    # \"SPv2+LG+sift+NN-rot-pixsfm-sci\",\n",
    "    # \"SIFT+SPv2-rot-pixsfm-sci\",\n",
    "\n",
    "    # \"DISK+SP-rot-pixsfm-sci\",\n",
    "    # \"DISK+SP+SG-rot-pixsfm-sci\",\n",
    "    \"DISK+SIFT+SP-rot-pixsfm-sci\",\n",
    "    # \"DISK+SIFT+SP+SG-rot-pixsfm-sci\",\n",
    "    # \"ALIKED2K+DISK+SIFT-rot-sci\",\n",
    "    \"ALIKED2K+DISK+SIFT-rot-pixsfm-sci\",\n",
    "    # \"ALIKED2K+DISK+SIFT-rot-pixsfm-force-sci\",\n",
    "    # \"ALIKED2Kh+DISKh+SIFT-rot-pixsfm-sci\",\n",
    "\n",
    "    # \"SP+SG-rot-sci\",\n",
    "    # \"SP-rot-sci\",\n",
    "    # \"SP+SG-rot-pixsfm-sci\",\n",
    "    # \"SP-rot-pixsfm-sci\",\n",
    "\n",
    "    # \"SP-rot\",\n",
    "    # \"SP+SG-rot\",\n",
    "    # \"SPh-rot\"\n",
    "\n",
    "    # \"SIFT-rot-pixsfm-sci\",\n",
    "    # \"ALIKED-rot-pixsfm-sci\",\n",
    "    # \"DISK-rot-pixsfm-sci\",\n",
    "    # \"ALIKED+SIFT-rot-pixsfm-sci\",\n",
    "    # \"DISK+SIFT-rot-pixsfm-sci\",\n",
    "    # \"ALIKED2K+DISK-rot-pixsfm-sci\",\n",
    "\n",
    "    # \"SP+SG\",\n",
    "    # \"SP\"\n",
    "]\n",
    "\n",
    "runs = [r for r in runs if r in fil_runs]\n",
    "\n",
    "# runs = sorted(runs)\n",
    "\n",
    "len(runs), len(fil_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "\n",
    "for ds in datasets.keys():\n",
    "    metrics[ds] = {}\n",
    "    for scene in datasets[ds]:\n",
    "        metrics[ds][scene] = {}\n",
    "\n",
    "        img_dir = f\"{DIR}/{MODE}/{ds}/{scene}/images\"\n",
    "        images = sorted(os.listdir(img_dir))\n",
    "        \n",
    "        metrics[ds][scene][\"images\"] = images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get models for each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in datasets.keys():\n",
    "    for scene in datasets[ds]:\n",
    "        for r in runs:\n",
    "            model_dir = out_dir / r / ds / scene / \"sparse\"\n",
    "            try:\n",
    "                model = pycolmap.Reconstruction(model_dir)\n",
    "            except ValueError:\n",
    "                print(f\"No model found for {ds}/{scene} in {r}\")\n",
    "\n",
    "                metrics[ds][scene][r] = {\n",
    "                    \"reg_images\": [],\n",
    "                    \"num_reg_images\": 0,\n",
    "                    \"model\": None,\n",
    "                }\n",
    "                continue\n",
    "\n",
    "            reg_images = [img.name for img in model.images.values()]\n",
    "            reg_images = sorted(reg_images)\n",
    "            metrics[ds][scene][r] = {\n",
    "                \"reg_images\": reg_images,\n",
    "                \"num_reg_images\": len(reg_images),\n",
    "                \"model\": model,\n",
    "            }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get eval for each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_score = {r: True for r in runs}\n",
    "\n",
    "for ds in datasets.keys():\n",
    "    for scene in datasets[ds]:\n",
    "        pbar = tqdm(runs, desc=f\"{ds}/{scene}\")\n",
    "        for r in pbar:\n",
    "            submission = Path(f\"{out_dir}/{r}/submission.csv\")\n",
    "            scores = Path(f\"{out_dir}/{r}/scores.json\")\n",
    "\n",
    "            if scores.exists() and not create_score[r]:\n",
    "                with open(scores, \"r\") as f:\n",
    "                    metrics[ds][scene][r][\"scores\"] = json.load(f)\n",
    "                continue\n",
    "\n",
    "            if submission.exists():\n",
    "                try:\n",
    "                    metrics[ds][scene][r][\"scores\"] = eval(\n",
    "                        submission, DIR, verbose=False, return_dict=True,\n",
    "                    )\n",
    "                    create_score[r] = False\n",
    "                except:\n",
    "                    metrics[ds][scene][r][\"scores\"] = None\n",
    "            else:\n",
    "                metrics[ds][scene][r][\"scores\"] = None\n",
    "\n",
    "            if metrics[ds][scene][r][\"scores\"] is not None:\n",
    "                # write scores to file\n",
    "                with open(f\"{out_dir}/{r}/scores.json\", \"w\") as f:\n",
    "                    json.dump(metrics[ds][scene][r][\"scores\"], f, indent=4)\n",
    "\n",
    "                    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in datasets:\n",
    "    for scene in datasets[ds]:\n",
    "        for r in runs:\n",
    "            timings_path = f\"{out_dir}/{r}/{ds}/{scene}/timings.json\"\n",
    "\n",
    "            timings = None\n",
    "            if os.path.exists(timings_path):\n",
    "                with open(timings_path, \"r\") as f:\n",
    "                    timings = json.load(f)\n",
    "                \n",
    "            metrics[ds][scene][r][\"timings\"] = timings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "\n",
    "pipline_steps = ['preprocessing', 'pairs-extraction', 'feature-extraction', 'feature-matching', 'create-ensemble', 'rotate-keypoints', 'sfm', 'localize-unreg']\n",
    "\n",
    "for r in runs:\n",
    "    row = ()\n",
    "    cols = ()\n",
    "    row += (r.split(\"-\")[0],)\n",
    "    # row += (r,)\n",
    "    cols += (\"run\",)\n",
    "\n",
    "    if metrics[\"heritage\"][\"cyprus\"][r][\"scores\"] is not None:\n",
    "        row += (metrics[\"heritage\"][\"cyprus\"][r][\"scores\"][\"mAA\"],)\n",
    "        cols += (\"mAA\",)\n",
    "\n",
    "\n",
    "        for ds in datasets:\n",
    "            scene = datasets[ds][0]\n",
    "            row += (metrics[ds][scene][r][\"scores\"][ds][\"mAA\"],)\n",
    "            cols += (f\"{ds}_mAA\",)\n",
    "            for scene in datasets[ds]:\n",
    "                row += (\n",
    "                    metrics[ds][scene][r][\"scores\"][ds][scene][\"mAA_t\"],\n",
    "                    metrics[ds][scene][r][\"scores\"][ds][scene][\"mAA_q\"],\n",
    "                    metrics[ds][scene][r][\"scores\"][ds][scene][\"mAA\"],\n",
    "                )\n",
    "                cols += (\n",
    "                    f\"{ds}_{scene}_mAA_t\",\n",
    "                    f\"{ds}_{scene}_mAA_q\",\n",
    "                    f\"{ds}_{scene}_mAA\",\n",
    "                )\n",
    "    else:\n",
    "        for ds in datasets:\n",
    "            row += (0,)\n",
    "            cols += (f\"{ds}_mAA\",)\n",
    "            for scene in datasets[ds]:\n",
    "                row += (0, 0, 0,)\n",
    "                cols += (\n",
    "                    f\"{ds}_{scene}_mAA_t\",\n",
    "                    f\"{ds}_{scene}_mAA_q\",\n",
    "                    f\"{ds}_{scene}_mAA\",\n",
    "                )\n",
    "\n",
    "    if metrics[\"heritage\"][\"cyprus\"][r][\"model\"] is not None:\n",
    "        for ds in datasets:\n",
    "            for scene in datasets[ds]:\n",
    "                row += (metrics[ds][scene][r][\"num_reg_images\"],)\n",
    "                cols += (f\"{ds}_{scene}_num_reg_images\",)\n",
    "    else:\n",
    "        for ds in datasets:\n",
    "            for scene in datasets[ds]:\n",
    "                row += (0,)\n",
    "                cols += (f\"{ds}_{scene}_num_reg_images\",)\n",
    "\n",
    "    for ds in datasets:\n",
    "        for scene in datasets[ds]:\n",
    "            if metrics[ds][scene][r][\"timings\"] is not None:\n",
    "                for step in pipline_steps:\n",
    "                    row += (metrics[ds][scene][r][\"timings\"][step],)\n",
    "                    cols += (f\"{ds}_{scene}_{step}_time\",)\n",
    "            else:\n",
    "                for step in pipline_steps:\n",
    "                    row += (0,)\n",
    "                    cols += (f\"{ds}_{scene}_{step}_time\",)\n",
    "                \n",
    "    df.append(row)\n",
    "\n",
    "df = pd.DataFrame(df, columns=cols)\n",
    "\n",
    "# df.sort_values(by=[\"run\"], inplace=True, ascending=True)\n",
    "df.set_index(\"run\", inplace=True, drop=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = sorted(df.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs = ['ALIKED', 'DISK', 'SIFT', 'ALIKED+SIFT', 'DISK+SIFT', 'ALIKED2K+DISK', 'ALIKED2K+DISK+SIFT']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get best runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"mAA\"]].sort_values(by=[\"mAA\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each run, print total mAA, mAA per dataset, mAA per scene\n",
    "header = \"| Config | Overall\"\n",
    "split = \"| --- | ---\"\n",
    "for ds in datasets:\n",
    "    header += f\" | {ds}\"\n",
    "    split += \" | ---\"\n",
    "\n",
    "for ds in datasets:\n",
    "    for scene in datasets[ds]:\n",
    "        header += f\" | {ds}/{scene}\"\n",
    "        split += \" | ---\"\n",
    "\n",
    "print(header + \"|\")\n",
    "print(split + \"|\")\n",
    "for r in runs:\n",
    "    line = f\"| {r} | {df.loc[r, 'mAA']:.3f}\"\n",
    "    for ds in datasets:\n",
    "        line += f\" | {df.loc[r, f'{ds}_mAA']:.3f}\"\n",
    "\n",
    "    for ds in datasets:\n",
    "        for scene in datasets[ds]:\n",
    "            line += f\" | {df.loc[r, f'{ds}_{scene}_mAA']:.3f}\"\n",
    "\n",
    "    print(line + \" |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\\\begin{{table}}[h!]\")\n",
    "print(f\"    \\\\centering\")\n",
    "print(\"    \\\\resizebox{\\\\textwidth}{!}{%\")\n",
    "print(\"         \\\\begin{tabular}{l l c c c}\")\n",
    "print(\"             \\\\toprule\")\n",
    "\n",
    "header = \"             Config\"\n",
    "for scene in datasets[\"heritage\"]:\n",
    "    header += f\" & {scene}\"\n",
    "\n",
    "header += \" & Overall \\\\\\\\\"\n",
    "\n",
    "print(header)\n",
    "\n",
    "\n",
    "split = \"             \\\\midrule\"\n",
    "for r in runs:\n",
    "    line = f\"             {r} & \"\n",
    "    for scene in datasets[\"heritage\"]:\n",
    "        mAA = df.loc[r, f\"heritage_{scene}_mAA\"]\n",
    "        line += f\" & {mAA:.3f}\"\n",
    "        \n",
    "\n",
    "    overall_mAA = df.loc[r, \"heritage_mAA\"]\n",
    "    line += f\" & {overall_mAA.mean():.3f}\"\n",
    "    header += f\" & Overall\"\n",
    "\n",
    "\n",
    "    print(line + \" \\\\\\\\\")\n",
    "\n",
    "\n",
    "print(\"             \\\\bottomrule\")\n",
    "\n",
    "print(\"         \\\\end{tabular}\")\n",
    "print(\"    }\")\n",
    "print(\"    \\\\caption{mAA scores for each scene and overall.}\")\n",
    "print(\"    \\\\label{tab:my_label}\")\n",
    "print(\"\\\\end{table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max(len(r) for r in runs)\n",
    "print(f\"\\\\begin{{table}}[h!]\")\n",
    "print(f\"    \\\\centering\")\n",
    "print(\"    \\\\resizebox{\\\\textwidth}{!}{%\")\n",
    "print(\"         \\\\begin{tabular}{l l c c c}\")\n",
    "print(\"             \\\\toprule\")\n",
    "\n",
    "best_per_col = []\n",
    "for scene in datasets[\"haiper\"]:\n",
    "    best_per_col.append(df[f\"haiper_{scene}_mAA\"].max())\n",
    "best_per_col.append(df[\"haiper_mAA\"].max())\n",
    "\n",
    "header = \"             Features & Matchers\"\n",
    "for scene in datasets[\"haiper\"]:\n",
    "    header += f\" & {scene}\"\n",
    "\n",
    "header += \" & Overall \\\\\\\\\"\n",
    "\n",
    "print(header)\n",
    "\n",
    "\n",
    "split = \"             \\\\midrule\"\n",
    "for r in runs:\n",
    "    offset = max_len - len(r)\n",
    "    line = f\"             {r:<{max_len}} & \"\n",
    "    for idx, scene in enumerate(datasets[\"haiper\"]):\n",
    "        mAA = df.loc[r, f\"haiper_{scene}_mAA\"]\n",
    "        line += f\" & {mAA:.3f}\" if mAA < best_per_col[idx] else f\" & \\\\textbf{{{mAA:.3f}}}\"\n",
    "\n",
    "\n",
    "    overall_mAA = df.loc[r, \"haiper_mAA\"]\n",
    "    line += f\" & {overall_mAA:.3f}\" if overall_mAA < best_per_col[-1] else f\" & \\\\textbf{{{overall_mAA:.3f}}}\"\n",
    "    header += f\" & Overall\"\n",
    "\n",
    "\n",
    "    print(line + \" \\\\\\\\\")\n",
    "\n",
    "\n",
    "print(\"             \\\\bottomrule\")\n",
    "\n",
    "print(\"         \\\\end{tabular}\")\n",
    "print(\"    }\")\n",
    "print(\"    \\\\caption{mAA scores for each scene and overall.}\")\n",
    "print(\"    \\\\label{tab:my_label}\")\n",
    "print(\"\\\\end{table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max(len(r) for r in runs)\n",
    "print(f\"\\\\begin{{table}}[h!]\")\n",
    "print(f\"    \\\\centering\")\n",
    "print(\"    \\\\resizebox{\\\\textwidth}{!}{%\")\n",
    "print(\"         \\\\begin{tabular}{l l c c}\")\n",
    "print(\"             \\\\toprule\")\n",
    "\n",
    "best_per_col = []\n",
    "for scene in datasets[\"urban\"]:\n",
    "    best_per_col.append(df[f\"urban_{scene}_mAA\"].max())\n",
    "best_per_col.append(df[\"urban_mAA\"].max())\n",
    "\n",
    "header = \"             Features & Matchers\"\n",
    "for scene in datasets[\"urban\"]:\n",
    "    header += f\" & {scene}\"\n",
    "\n",
    "header += \" & Overall \\\\\\\\\"\n",
    "\n",
    "print(header)\n",
    "\n",
    "\n",
    "split = \"             \\\\midrule\"\n",
    "for r in runs:\n",
    "    offset = max_len - len(r)\n",
    "    line = f\"             {r:<{max_len}} & \"\n",
    "    for idx, scene in enumerate(datasets[\"urban\"]):\n",
    "        mAA = df.loc[r, f\"urban_{scene}_mAA\"]\n",
    "        line += f\" & {mAA:.3f}\" if mAA < best_per_col[idx] else f\" & \\\\textbf{{{mAA:.3f}}}\"\n",
    "\n",
    "\n",
    "    overall_mAA = df.loc[r, \"urban_mAA\"]\n",
    "    line += f\" & {overall_mAA:.3f}\" if overall_mAA < best_per_col[-1] else f\" & \\\\textbf{{{overall_mAA:.3f}}}\"\n",
    "    header += f\" & Overall\"\n",
    "\n",
    "\n",
    "    print(line + \" \\\\\\\\\")\n",
    "\n",
    "\n",
    "print(\"             \\\\bottomrule\")\n",
    "\n",
    "print(\"         \\\\end{tabular}\")\n",
    "print(\"    }\")\n",
    "print(\"    \\\\caption{mAA scores for each scene and overall.}\")\n",
    "print(\"    \\\\label{tab:my_label}\")\n",
    "print(\"\\\\end{table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the best run for each dataset and scene from the dataframe\n",
    "\n",
    "max_str = max(len(ds) + len(scene) for ds in datasets.keys() for scene in datasets[ds]) + 1\n",
    "\n",
    "for ds in datasets:\n",
    "    for scene in datasets[ds]:\n",
    "        name = df.loc[:, f\"{ds}_{scene}_mAA\"].idxmax()\n",
    "        # name = df.iloc[idx].run\n",
    "        mAA = df.loc[name, f\"{ds}_{scene}_mAA\"]\n",
    "        print(f\"{f'{ds}/{scene}':{max_str}}: {mAA:.4f} ({name})\")\n",
    "\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# get the best run for each dataset from the dataframe\n",
    "for ds in datasets:\n",
    "    name = df.loc[:, f\"{ds}_mAA\"].idxmax()\n",
    "    # name = df.iloc[idx].run\n",
    "    mAA = df.loc[name, f\"{ds}_mAA\"]\n",
    "    print(f\"{ds:{max_str}}: {mAA:.4f} ({name})\")\n",
    "\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# get the best run from the dataframe\n",
    "name = df.loc[:, \"mAA\"].idxmax()\n",
    "# name = df.iloc[idx].run\n",
    "mAA = df.loc[name, \"mAA\"]\n",
    "print(f\"{'all':{max_str}}: {mAA:.4f} ({name})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = runs[-3]\n",
    "\n",
    "print(name)\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for ds in datasets:\n",
    "    for scene in datasets[ds]:\n",
    "        mAA = df.loc[name, f\"{ds}_{scene}_mAA\"]\n",
    "        print(f\"{f'{ds}/{scene}':{max_str}}: {mAA:.4f} ({name})\")\n",
    "\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# get the best run for each dataset from the dataframe\n",
    "for ds in datasets:\n",
    "    mAA = df.loc[name, f\"{ds}_mAA\"]\n",
    "    print(f\"{ds:{max_str}}: {mAA:.4f} ({name})\")\n",
    "\n",
    "print(\"-\" * 80)\n",
    "\n",
    "mAA = df.loc[name, \"mAA\"]\n",
    "print(f\"{'all':{max_str}}: {mAA:.4f} ({name})\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "name_map = {\n",
    "    'ALIKED2K+DISK+SIFT-rot-pixsfm-force-sci': 'Naive',\n",
    "    'ALIKED2K+DISK+SIFT-rot-pixsfm-sci': 'Final',\n",
    "    'ALIKED2K+DISK+SIFT-rot-sci': 'No PixSFM',\n",
    "}\n",
    "name_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(datasets), len(datasets[\"heritage\"])+1, figsize=(40, 25))\n",
    "\n",
    "for i, ds in enumerate(datasets.keys()):\n",
    "    for r in runs:\n",
    "        name = df.loc[r, \"run\"]\n",
    "        ds_mAA = df.loc[r, f\"{ds}_mAA\"]\n",
    "        mAA = df.loc[r, \"mAA\"]\n",
    "        ax[i, 0].bar(\n",
    "            # name_map[name],\n",
    "            name,\n",
    "            ds_mAA,\n",
    "            alpha=0.3,\n",
    "            label=\"mAA\" if r == df.index[-1] else \"\",\n",
    "        )\n",
    "\n",
    "        ax[i, 0].hlines(\n",
    "            mAA,\n",
    "            df.index.tolist().index(r) - 0.4,\n",
    "            df.index.tolist().index(r) + 0.4,\n",
    "            color=\"red\",\n",
    "            label=\"Overall mAA\" if r == df.index[-1] else \"\",\n",
    "        )\n",
    "\n",
    "        # rotate the xticklabels\n",
    "        # for tick in ax[i, 0].get_xticklabels():\n",
    "        #     tick.set_rotation(25)\n",
    "        #     tick.set_ha(\"right\")\n",
    "\n",
    "        # font size\n",
    "        ax[i, 0].tick_params(axis=\"both\", which=\"major\", labelsize=20)\n",
    "\n",
    "\n",
    "    ax[i, 0].set_ylim([0.5, 1])\n",
    "    ax[i, 0].set_title(ds, fontsize=28)\n",
    "    ax[i, 0].legend(fontsize=20, loc=\"lower right\")\n",
    "\n",
    "\n",
    "    for j, scene in enumerate(datasets[ds]):\n",
    "        for r in runs:\n",
    "            name = df.loc[r, \"run\"]\n",
    "            mAA = df.loc[r, f\"{ds}_{scene}_mAA\"]\n",
    "            mAA_t = df.loc[r, f\"{ds}_{scene}_mAA_t\"]\n",
    "            mAA_q = df.loc[r, f\"{ds}_{scene}_mAA_q\"]\n",
    "\n",
    "            ax[i, j+1].bar(\n",
    "                # name_map[name],\n",
    "                name,\n",
    "                mAA,\n",
    "                alpha=0.3,\n",
    "                label=\"mAA\" if r == df.index[-1] else \"\",\n",
    "            )\n",
    "\n",
    "            ax[i, j+1].hlines(\n",
    "                mAA_t,\n",
    "                df.index.tolist().index(r) - 0.4,\n",
    "                df.index.tolist().index(r) + 0.4,\n",
    "                color=\"b\",\n",
    "                label=\"mAA_t\" if r == df.index[-1] else \"\",\n",
    "            )\n",
    "\n",
    "            ax[i, j+1].hlines(\n",
    "                mAA_q,\n",
    "                df.index.tolist().index(r) - 0.4,\n",
    "                df.index.tolist().index(r) + 0.4,\n",
    "                color=\"r\",\n",
    "                label=\"mAA_q\" if r == df.index[-1] else \"\",\n",
    "            )\n",
    "\n",
    "            # rotate x-axis labels and align them to the right\n",
    "            # for tick in ax[i, j+1].get_xticklabels():\n",
    "            #     tick.set_rotation(25)\n",
    "            #     tick.set_ha(\"right\")\n",
    "                \n",
    "            # font size\n",
    "            ax[i, j+1].tick_params(axis=\"both\", which=\"major\", labelsize=20)\n",
    "\n",
    "        ax[i, j+1].set_ylim(0.5, 1)\n",
    "        ax[i, j+1].set_title(f\"{ds}/{scene}\", fontsize=28)\n",
    "        ax[i, j+1].legend(fontsize=20, loc=\"lower right\")\n",
    "            \n",
    "for r in runs:\n",
    "    name = df.loc[r, \"run\"]\n",
    "    ax[2, 2].bar(\n",
    "        # name_map[name],\n",
    "        name,\n",
    "        0,\n",
    "        alpha=0.3,\n",
    "        label=name,\n",
    "    )\n",
    "\n",
    "    ax[2, 2].legend(fontsize=38, loc=[0.5, 0.5])\n",
    "\n",
    "    # turn off the axis\n",
    "    ax[2, 2].axis(\"off\")\n",
    "\n",
    "ax[2, 3].axis(\"off\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.savefig(\"/Users/alexanderveicht/Desktop/run_comp.pdf\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = [\n",
    "    'ALIKED2K+DISK+SIFT-rot-sci',\n",
    "    'ALIKED2K+DISK+SIFT-rot-pixsfm-force-sci',\n",
    "    'ALIKED2K+DISK+SIFT-rot-pixsfm-sci',\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 14))\n",
    "\n",
    "scene = \"cyprus\"\n",
    "ds = \"heritage\"\n",
    "\n",
    "for idx, r in enumerate(runs):\n",
    "    name = df.loc[r, \"run\"]\n",
    "    mAA = df.loc[r, f\"{ds}_{scene}_mAA\"]\n",
    "    mAA_t = df.loc[r, f\"{ds}_{scene}_mAA_t\"]\n",
    "    mAA_q = df.loc[r, f\"{ds}_{scene}_mAA_q\"]\n",
    "\n",
    "    ax[0].bar(\n",
    "        name_map[name],\n",
    "        mAA,\n",
    "        alpha=0.3,\n",
    "        label=\"mAA\" if r == df.index[-1] else \"\",\n",
    "    )\n",
    "\n",
    "    ax[0].hlines(\n",
    "        mAA_t,\n",
    "        idx - 0.4,\n",
    "        idx + 0.4,\n",
    "        color=\"b\",\n",
    "        label=\"mAA_t\" if r == df.index[-1] else \"\",\n",
    "    )\n",
    "\n",
    "    ax[0].hlines(\n",
    "        mAA_q,\n",
    "        idx - 0.4,\n",
    "        idx + 0.4,\n",
    "        color=\"r\",\n",
    "        label=\"mAA_q\" if r == df.index[-1] else \"\",\n",
    "    )\n",
    "\n",
    "    # rotate x-axis labels and align them to the right\n",
    "    # for tick in ax[i, j+1].get_xticklabels():\n",
    "    #     tick.set_rotation(25)\n",
    "    #     tick.set_ha(\"right\")\n",
    "            \n",
    "    # font size\n",
    "    ax[0].tick_params(axis=\"both\", which=\"major\", labelsize=20)\n",
    "\n",
    "ax[0].set_ylim(0.6, 1)\n",
    "ax[0].set_title(f\"{ds}/{scene}\", fontsize=28)\n",
    "ax[0].legend(fontsize=18, loc=\"lower right\")\n",
    "\n",
    "\n",
    "runs = [\n",
    "    'ALIKED2K+DISK+SIFT-rot-sci',\n",
    "    'ALIKED2K+DISK+SIFT-rot-pixsfm-sci',\n",
    "    'ALIKED2K+DISK+SIFT-rot-pixsfm-sci',\n",
    "]\n",
    "\n",
    "names = [\n",
    "    \"w/o PixSFM\",\n",
    "    \"Naive\",\n",
    "    \"Final\",\n",
    "]\n",
    "\n",
    "scene = \"kyiv-puppet-theater\"\n",
    "ds = \"urban\"\n",
    "\n",
    "for idx, r in enumerate(runs):\n",
    "    name = df.loc[r, \"run\"]\n",
    "    mAA = df.loc[r, f\"{ds}_{scene}_mAA\"]\n",
    "    mAA_t = df.loc[r, f\"{ds}_{scene}_mAA_t\"]\n",
    "    mAA_q = df.loc[r, f\"{ds}_{scene}_mAA_q\"]\n",
    "\n",
    "    ax[1].bar(\n",
    "        names[idx],\n",
    "        mAA,\n",
    "        alpha=0.3,\n",
    "        label=\"mAA\" if r == df.index[-1] else \"\",\n",
    "    )\n",
    "\n",
    "    ax[1].hlines(\n",
    "        mAA_t,\n",
    "        idx - 0.4,\n",
    "        idx + 0.4,\n",
    "        color=\"b\",\n",
    "        label=\"mAA_t\" if r == df.index[-1] else \"\",\n",
    "    )\n",
    "\n",
    "    ax[1].hlines(\n",
    "        mAA_q,\n",
    "        idx - 0.4,\n",
    "        idx + 0.4,\n",
    "        color=\"r\",\n",
    "        label=\"mAA_q\" if r == df.index[-1] else \"\",\n",
    "    )\n",
    "\n",
    "    # rotate x-axis labels and align them to the right\n",
    "    # for tick in ax[i, j+1].get_xticklabels():\n",
    "    #     tick.set_rotation(25)\n",
    "    #     tick.set_ha(\"right\")\n",
    "            \n",
    "    # font size\n",
    "    ax[1].tick_params(axis=\"both\", which=\"major\", labelsize=20)\n",
    "\n",
    "ax[1].set_ylim(0.6, 1)\n",
    "ax[1].set_title(f\"{ds}/{scene}\", fontsize=28)\n",
    "ax[1].legend(fontsize=18, loc=\"lower right\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot num registered images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(datasets), len(datasets[\"heritage\"]), figsize=(20, 20))\n",
    "\n",
    "for i, ds in enumerate(datasets.keys()):\n",
    "    for j, scene in enumerate(datasets[ds]):\n",
    "        for r in df.index:\n",
    "            name = df.loc[r, \"run\"]\n",
    "            n_reg = df.loc[r, f\"{ds}_{scene}_num_reg_images\"]\n",
    "            \n",
    "            ax[i, j].bar(\n",
    "                r,\n",
    "                n_reg,\n",
    "                label=f\"{r}\",\n",
    "            )\n",
    "\n",
    "            ax[i, j].hlines(\n",
    "                len(metrics[ds][scene][\"images\"]),\n",
    "                -1,\n",
    "                len(runs),\n",
    "                label=f\"GT ({len(metrics[ds][scene]['images'])})\",\n",
    "                colors=\"r\",\n",
    "            )\n",
    "            \n",
    "            ax[i, j].set_title(f\"{ds}/{scene}\")\n",
    "\n",
    "            # rotate x-axis labels and align them to the right\n",
    "            for tick in ax[i, j].get_xticklabels():\n",
    "                tick.set_rotation(45)\n",
    "                tick.set_ha(\"right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(datasets), len(datasets[\"heritage\"]), figsize=(30, 20))\n",
    "\n",
    "for i, ds in enumerate(datasets.keys()):\n",
    "    for j, scene in enumerate(datasets[ds]):\n",
    "        bool_img_run = np.zeros((len(runs), len(metrics[ds][scene][\"images\"])))\n",
    "        \n",
    "        for r_idx, r in enumerate(runs):\n",
    "            if r not in metrics[ds][scene].keys():\n",
    "                continue\n",
    "\n",
    "            for img in metrics[ds][scene][r][\"reg_images\"]:\n",
    "                img_idx = metrics[ds][scene][\"images\"].index(img)\n",
    "                bool_img_run[r_idx, img_idx] = 1\n",
    "\n",
    "        sns.heatmap(\n",
    "            bool_img_run,\n",
    "            ax=ax[i, j],\n",
    "            cbar=False,\n",
    "            vmin=0,\n",
    "            vmax=1,\n",
    "            yticklabels=runs,\n",
    "        )\n",
    "        ax[i, j].set_title(f\"{ds}/{scene}\")\n",
    "\n",
    "# add more space between plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(datasets), len(datasets[\"heritage\"])+1, figsize=(30, 20))\n",
    "\n",
    "cmap = plt.get_cmap(\"tab20\") \n",
    "\n",
    "for i, ds in enumerate(datasets.keys()):\n",
    "    for r in df.index:\n",
    "        name = df.loc[r, \"run\"]\n",
    "        mean_times = [0 for _ in pipline_steps]\n",
    "        for scene in datasets[ds]:\n",
    "            for idx, step in enumerate(pipline_steps):\n",
    "                mean_times[idx] += df.loc[r, f\"{ds}_{scene}_{step}_time\"]\n",
    "        mean_times = [t / len(datasets[ds]) for t in mean_times]\n",
    "\n",
    "        cumsum = 0\n",
    "        for idx, step in enumerate(pipline_steps):\n",
    "            ax[i, 0].bar(\n",
    "                name,\n",
    "                mean_times[idx],\n",
    "                bottom=cumsum,\n",
    "                label=step if r == df.index[-1] else \"\",\n",
    "                color=cmap(idx),\n",
    "            )\n",
    "            cumsum += mean_times[idx]\n",
    "\n",
    "        # rotate the xticklabels\n",
    "        for tick in ax[i, 0].get_xticklabels():\n",
    "            tick.set_rotation(45)\n",
    "            tick.set_ha(\"right\")\n",
    "\n",
    "    ax[i, 0].set_title(ds)\n",
    "    ax[i, 0].legend()\n",
    "\n",
    "\n",
    "    for j, scene in enumerate(datasets[ds]):\n",
    "        for r in df.index:\n",
    "            name = df.loc[r, \"run\"]\n",
    "            mean_times = [0 for _ in pipline_steps]\n",
    "            for idx, step in enumerate(pipline_steps):\n",
    "                mean_times[idx] += df.loc[r, f\"{ds}_{scene}_{step}_time\"]\n",
    "            mean_times = [t / len(datasets[ds]) for t in mean_times]\n",
    "\n",
    "            cumsum = 0\n",
    "            for idx, step in enumerate(pipline_steps):\n",
    "                ax[i, j+1].bar(\n",
    "                    name,\n",
    "                    mean_times[idx],\n",
    "                    bottom=cumsum,\n",
    "                    label=step if r == df.index[-1] else \"\",\n",
    "                    color=cmap(idx),\n",
    "                )\n",
    "                cumsum += mean_times[idx]\n",
    "\n",
    "            # rotate x-axis labels and align them to the right\n",
    "            for tick in ax[i, j+1].get_xticklabels():\n",
    "                tick.set_rotation(45)\n",
    "                tick.set_ha(\"right\")\n",
    "\n",
    "        ax[i, j+1].set_title(f\"{ds}/{scene}\")\n",
    "        ax[i, j+1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create overall runtime plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 7))\n",
    "\n",
    "legend_steps = ['preprocessing', 'pairs-extraction', 'feature-extraction', 'feature-matching', 'create-ensemble', 'sfm', 'localize-unreg']\n",
    "\n",
    "cmap = plt.get_cmap(\"tab20\")\n",
    "\n",
    "for r in runs: #['SP-rot-sci', 'SP-rot-pixsfm-sci', 'SP+SG-rot-sci', 'SP+SG-rot-pixsfm-sci', ]:\n",
    "    name = df.loc[r, \"run\"]\n",
    "    mean_times = [0 for _ in pipline_steps]\n",
    "    for ds in datasets.keys():\n",
    "        for scene in datasets[ds]:\n",
    "            for idx, step in enumerate(pipline_steps):\n",
    "                mean_times[idx] += df.loc[r, f\"{ds}_{scene}_{step}_time\"]\n",
    "    # mean_times = [t / len(df) for t in mean_times]\n",
    "\n",
    "    cumsum = 0\n",
    "    for idx, step in enumerate(pipline_steps):\n",
    "        ax.bar(\n",
    "            name if name != \"SP\" else \"SP+LG\",\n",
    "            mean_times[idx],\n",
    "            bottom=cumsum,\n",
    "            label=step if r == df.index[-1] and step in legend_steps else \"\",\n",
    "            color=cmap(idx),\n",
    "        )\n",
    "        cumsum += mean_times[idx]\n",
    "\n",
    "        if step == \"feature-matching\":\n",
    "            minutes = np.floor(mean_times[idx] / 60)\n",
    "            sec = mean_times[idx] % 60\n",
    "            print(f\"{name}: {minutes:.0f} min {sec:.0f} sec\")\n",
    "    # rotate the xticklabels\n",
    "    # for tick in ax.get_xticklabels():\n",
    "        # tick.set_rotation(20)\n",
    "        # tick.set_ha(\"right\")\n",
    "\n",
    "    # divide by 60 to get minutes\n",
    "    def divide_by_60(x, pos):\n",
    "        return f'{x/60:.0f}'\n",
    "\n",
    "    # Create a formatter using the custom function\n",
    "    formatter = ticker.FuncFormatter(divide_by_60)\n",
    "\n",
    "    # Apply the formatter to the x-axis\n",
    "    ax.yaxis.set_major_formatter(formatter)  \n",
    "\n",
    "    # increase fonts\n",
    "    ax.tick_params(axis='both', which='major', labelsize=18)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=18)\n",
    "\n",
    "    ax.set_ylabel(\"Runtime (min)\", fontsize=18)\n",
    "\n",
    "ax.set_ylim([0, 30*60])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend(fontsize=18)\n",
    "plt.savefig(\"/Users/alexanderveicht/Desktop/runtime.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for ds in datasets.keys():\n",
    "    for j, scene in enumerate(datasets[ds]):\n",
    "        image_names = metrics[ds][scene][\"images\"]\n",
    "\n",
    "        pbar = tqdm(runs, desc=f\"{ds}/{scene}\")\n",
    "\n",
    "        rows = np.sqrt(len(runs))\n",
    "        cols = np.ceil(len(runs) / rows)\n",
    "        fig, ax = plt.subplots(int(rows+1), int(cols), figsize=(5 * cols, 5 * rows))\n",
    "\n",
    "        for r_idx, r in enumerate(pbar):\n",
    "\n",
    "            scene_dir = Path(f\"{out_dir}/{r}/{ds}/{scene}\")\n",
    "\n",
    "            matches = scene_dir / \"matches.h5\"\n",
    "\n",
    "            if not matches.exists():\n",
    "                continue\n",
    "\n",
    "            pairs = sorted(list_h5_names(matches))\n",
    "\n",
    "            match_matrix = -np.ones([len(image_names), len(image_names)])\n",
    "            for pair in pairs:\n",
    "                name0, name1 = pair.split(\"/\")\n",
    "                idx0, idx1 = image_names.index(name0), image_names.index(name1)\n",
    "                m, sc = get_matches(matches, name0, name1)\n",
    "                match_matrix[idx0, idx1] = match_matrix[idx1, idx0] = m.shape[0]\n",
    "\n",
    "            sns.heatmap(\n",
    "                match_matrix,\n",
    "                ax=ax[int(r_idx // cols), int(r_idx % cols)],\n",
    "                cbar=True,\n",
    "                cmap=\"hot\",\n",
    "                mask=match_matrix < 0,\n",
    "            )\n",
    "\n",
    "            ax[int(r_idx // cols), int(r_idx % cols)].set_title(r)\n",
    "\n",
    "        plt.suptitle(f\"{ds}/{scene}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for ds in datasets.keys():\n",
    "    for j, scene in enumerate(datasets[ds]):\n",
    "        image_names = metrics[ds][scene][\"images\"]\n",
    "\n",
    "        pbar = tqdm(runs, desc=f\"{ds}/{scene}\")\n",
    "\n",
    "        rows = np.sqrt(len(runs))\n",
    "        cols = np.ceil(len(runs) / rows)\n",
    "        fig, ax = plt.subplots(int(rows+1), int(cols), figsize=(5 * cols, 5 * rows))\n",
    "\n",
    "        for r_idx, r in enumerate(pbar):\n",
    "\n",
    "            scene_dir = Path(f\"{out_dir}/{r}/{ds}/{scene}\")\n",
    "\n",
    "            matches = scene_dir / \"matches.h5\"\n",
    "\n",
    "            if not matches.exists():\n",
    "                continue\n",
    "\n",
    "            reg_images = metrics[ds][scene][r][\"reg_images\"]\n",
    "            unreg_images = [img for img in image_names if img not in reg_images]\n",
    "\n",
    "            if not unreg_images or len(reg_images) == 0:\n",
    "                continue\n",
    "\n",
    "\n",
    "            pairs = sorted(list_h5_names(matches))\n",
    "\n",
    "            match_matrix = -np.ones([len(unreg_images), len(reg_images)])\n",
    "            for pair in pairs:\n",
    "                name0, name1 = pair.split(\"/\")\n",
    "                m, sc = get_matches(matches, name0, name1)\n",
    "\n",
    "                if name0 in unreg_images and name1 in reg_images:\n",
    "                    idx0, idx1 = unreg_images.index(name0), reg_images.index(name1)\n",
    "                    match_matrix[idx0, idx1] = m.shape[0]\n",
    "\n",
    "                elif name1 in unreg_images and name0 in reg_images:\n",
    "                    idx0, idx1 = unreg_images.index(name1), reg_images.index(name0)\n",
    "                    match_matrix[idx0, idx1] = m.shape[0]                \n",
    "\n",
    "            sns.heatmap(\n",
    "                match_matrix,\n",
    "                ax=ax[int(r_idx // cols), int(r_idx % cols)],\n",
    "                cbar=True,\n",
    "                cmap=\"hot\",\n",
    "                mask=(match_matrix < 0),\n",
    "            )\n",
    "\n",
    "            ax[int(r_idx // cols), int(r_idx % cols)].set_title(r)\n",
    "            ax[int(r_idx // cols), int(r_idx % cols)].set_xlabel(\"reg\")\n",
    "            ax[int(r_idx // cols), int(r_idx % cols)].set_ylabel(\"unreg\")\n",
    "\n",
    "        plt.suptitle(f\"{ds}/{scene}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "megadepth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
