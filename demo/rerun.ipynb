{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f3ca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "import zipfile\n",
    "from argparse import ArgumentParser\n",
    "from pathlib import Path\n",
    "from typing import Final\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import requests\n",
    "import pycolmap\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import rerun as rr\n",
    "\n",
    "rr.init(\"RECONSTRUCTION\")\n",
    "\n",
    "\n",
    "folder_path = '/home/sergio/programming/misc/image-matching-challenge-2024/Hierarchical-Localization/'\n",
    "\n",
    "# smf_path = Path(folder_path, 'datasets/image-matching-challenge-2024/train/dioscuri/sfm').resolve()\n",
    "# imgs_path = Path(folder_path, 'datasets/image-matching-challenge-2024/train/dioscuri/images').resolve()\n",
    "\n",
    "smf_path = Path(folder_path, '../temp/aliked2k+disk+sift-rot-pixsfm-sci-loc/dioscuri/dioscuri/sparse/').resolve()\n",
    "imgs_path = Path(folder_path, '../temp/aliked2k+disk+sift-rot-pixsfm-sci-loc/dioscuri/dioscuri/images/').resolve()\n",
    "\n",
    "# smf_path = Path(folder_path, '../temp/aliked2k+disk+sift-rot-pixsfm-sci-loc/church/church/sparse/').resolve()\n",
    "# imgs_path = Path(folder_path, '../temp/aliked2k+disk+sift-rot-pixsfm-sci-loc/church/church/images/').resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f061a7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DESCRIPTION = \"\"\"\n",
    "# Sparse Reconstruction by COLMAP\n",
    "This example was generated from the output of a sparse reconstruction done with COLMAP.\n",
    "\n",
    "[COLMAP](https://colmap.github.io/index.html) is a general-purpose Structure-from-Motion (SfM) and Multi-View Stereo\n",
    "(MVS) pipeline with a graphical and command-line interface.\n",
    "\n",
    "In this example a short video clip has been processed offline by the COLMAP pipeline, and we use Rerun to visualize the\n",
    "individual camera frames, estimated camera poses, and resulting point clouds over time.\n",
    "\n",
    "## How it was made\n",
    "The full source code for this example is available\n",
    "[on GitHub](https://github.com/rerun-io/rerun/blob/latest/examples/python/structure_from_motion/main.py).\n",
    "\n",
    "### Images\n",
    "The images are logged through the [rr.Image archetype](https://www.rerun.io/docs/reference/types/archetypes/image)\n",
    "to the [camera/image entity](recording://camera/image).\n",
    "\n",
    "### Cameras\n",
    "The images stem from pinhole cameras located in the 3D world. To visualize the images in 3D, the pinhole projection has\n",
    "to be logged and the camera pose (this is often referred to as the intrinsics and extrinsics of the camera,\n",
    "respectively).\n",
    "\n",
    "The [rr.Pinhole archetype](https://www.rerun.io/docs/reference/types/archetypes/pinhole) is logged to\n",
    "the [camera/image entity](recording://camera/image) and defines the intrinsics of the camera. This defines how to go\n",
    "from the 3D camera frame to the 2D image plane. The extrinsics are logged as an\n",
    "[rr.Transform3D archetype](https://www.rerun.io/docs/reference/types/archetypes/transform3d) to the\n",
    "[camera entity](recording://camera).\n",
    "\n",
    "### Reprojection error\n",
    "For each image a [rr.Scalar archetype](https://www.rerun.io/docs/reference/types/archetypes/scalar)\n",
    "containing the average reprojection error of the keypoints is logged to the\n",
    "[plot/avg_reproj_err entity](recording://plot/avg_reproj_err).\n",
    "\n",
    "### 2D points\n",
    "The 2D image points that are used to triangulate the 3D points are visualized by logging\n",
    "[rr.Points3D archetype](https://www.rerun.io/docs/reference/types/archetypes/points2d)\n",
    "to the [camera/image/keypoints entity](recording://camera/image/keypoints). Note that these keypoints are a child of the\n",
    "[camera/image entity](recording://camera/image), since the points should show in the image plane.\n",
    "\n",
    "### Colored 3D points\n",
    "The colored 3D points were added to the scene by logging the\n",
    "[rr.Points3D archetype](https://www.rerun.io/docs/reference/types/archetypes/points3d)\n",
    "to the [points entity](recording://points):\n",
    "```python\n",
    "rr.log(\"points\", rr.Points3D(points, colors=point_colors), rr.AnyValues(error=point_errors))\n",
    "```\n",
    "**Note:** we added some [custom per-point errors](recording://points) that you can see when you\n",
    "hover over the points in the 3D view.\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3446342e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ea1700",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTER_MIN_VISIBLE = 60\n",
    "def scale_camera(camera, resize: tuple[int, int]) -> tuple[pycolmap.Camera, npt.NDArray[np.float_]]:\n",
    "    \"\"\"Scale the camera intrinsics to match the resized image.\"\"\"\n",
    "    assert camera.model == \"PINHOLE\"\n",
    "    new_width = resize[0]\n",
    "    new_height = resize[1]\n",
    "    scale_factor = np.array([new_width / camera.width, new_height / camera.height])\n",
    "\n",
    "    # For PINHOLE camera model, params are: [focal_length_x, focal_length_y, principal_point_x, principal_point_y]\n",
    "    new_params = np.append(camera.params[:2] * scale_factor, camera.params[2:] * scale_factor)\n",
    "\n",
    "    return (pycolmap.Camera(camera.id, camera.model, new_width, new_height, new_params), scale_factor)\n",
    "\n",
    "\n",
    "\n",
    "def read_and_log_sparse_reconstruction(rec_path: Path, img_path: Path, filter_output: bool, resize: tuple[int, int] | None) -> None:\n",
    "    print(\"Reading sparse COLMAP reconstruction\")\n",
    "    reconstruction = pycolmap.Reconstruction(rec_path)\n",
    "    cameras = reconstruction.cameras\n",
    "    images = reconstruction.images\n",
    "    points3D = reconstruction.points3D\n",
    "    print(\"Building visualization by logging to Rerun\")\n",
    "\n",
    "    if filter_output:\n",
    "        # Filter out noisy points\n",
    "        points3D = {id: point for id, point in points3D.items() if point.color.any() and len(point.image_ids) > 2}\n",
    "\n",
    "    # rr.log(\"description\", rr.TextDocument(DESCRIPTION, media_type=rr.MediaType.MARKDOWN), timeless=True)\n",
    "    rr.log(\"/\", rr.ViewCoordinates.RIGHT_HAND_Y_DOWN, timeless=True)\n",
    "    rr.log(\"plot/avg_reproj_err\", rr.SeriesLine(color=[240, 45, 58]), timeless=True)\n",
    "    \n",
    "    # Iterate through images (video frames) logging data related to each frame.\n",
    "    ii=0\n",
    "    \n",
    "    list_visible_xyzs = []\n",
    "    all_point = []\n",
    "    all_point_colors = []\n",
    "    all_point_errors = []\n",
    "    for image in tqdm(sorted(images.values(), key=lambda im: im.name)):  # type: ignore[no-any-return]\n",
    "        image_file = img_path / image.name.replace('.jpg', '.png')\n",
    "        if not os.path.exists(image_file):\n",
    "            continue\n",
    "        # print (image_file)\n",
    "\n",
    "        # COLMAP sets image ids that don't match the original video frame\n",
    "        idx_match = re.search(r\"\\d+\", image.name)\n",
    "        assert idx_match is not None\n",
    "        frame_idx = int(idx_match.group(0))\n",
    "\n",
    "\n",
    "        camera = cameras[image.camera_id]\n",
    "        if resize:\n",
    "            camera, scale_factor = scale_camera(camera, resize)\n",
    "        else:\n",
    "            scale_factor = np.array([1.0, 1.0])\n",
    "\n",
    "        visible_ids = [id_ for id_ in points3D.keys() if image.has_point3D(id_) ]\n",
    "        \n",
    "\n",
    "        if filter_output and len(visible_ids) < FILTER_MIN_VISIBLE:\n",
    "            continue\n",
    "\n",
    "        visible_xyzs = [points3D[idx] for idx in visible_ids]\n",
    "        visible_xys = np.array([x.xy for x in image.get_valid_points2D()])\n",
    "        \n",
    "        list_visible_xyzs.extend(visible_xyzs)\n",
    "        \n",
    "        if resize:\n",
    "            visible_xys *= scale_factor\n",
    "\n",
    "        rr.set_time_sequence(\"frame\", frame_idx)\n",
    "        try:\n",
    "            points = [point.xyz for point in visible_xyzs]\n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "            continue\n",
    "        point_colors = [point.color for point in visible_xyzs]\n",
    "        point_errors = [point.error for point in visible_xyzs]\n",
    "\n",
    "        rr.log(\"plot/avg_reproj_err\", rr.Scalar(np.mean(point_errors)))\n",
    "\n",
    "        rr.log(\"points\", rr.Points3D(points, colors=point_colors), rr.AnyValues(error=point_errors))    \n",
    "        \n",
    "        all_point.extend(points)\n",
    "        all_point_colors.extend(point_colors)\n",
    "        all_point_errors.extend(point_errors)    \n",
    "        \n",
    "        rr.log(\"points\", rr.Points3D(all_point, colors=all_point_colors), rr.AnyValues(error=all_point_errors))    \n",
    "        \n",
    "        # COLMAP's camera transform is \"camera from world\"\n",
    "        try:\n",
    "            rr.log(\n",
    "                \"camera\", rr.Transform3D(translation=image.cam_from_world.translation,\n",
    "                                        rotation=rr.Quaternion(xyzw=image.cam_from_world.rotation.quat), from_parent=True)\n",
    "            )\n",
    "        except:\n",
    "            print(f\"Image {frame_idx} not valid\")\n",
    "            \n",
    "        rr.log(\"camera\", rr.ViewCoordinates.RFD, timeless=True)  # X=Right, Y=Down, Z=Forward\n",
    "       \n",
    "\n",
    "        \n",
    "        try:\n",
    "            # Log camera intrinsics\n",
    "            # assert str(camera.model) in  [\"CameraModelId.SIMPLE_PINHOLE\", \"CameraModelId.PINHOLE\"]\n",
    "            if str(camera.model) == \"CameraModelId.SIMPLE_PINHOLE\":\n",
    "                print(\"camera pin hole\")\n",
    "                rr.log(\n",
    "                    \"camera/image\",\n",
    "                    rr.Pinhole(\n",
    "                        resolution=[camera.width, camera.height],\n",
    "                        focal_length=[camera.params[0], camera.params[0]],\n",
    "                        principal_point=camera.params[1:],\n",
    "                    ),\n",
    "                )\n",
    "            else:\n",
    "                print(\"other camera\")\n",
    "                rr.log(\n",
    "                    \"camera/image\",\n",
    "                    rr.Pinhole(\n",
    "                        resolution=[camera.width, camera.height],\n",
    "                        focal_length=camera.params[:2],\n",
    "                        principal_point=camera.params[2:],\n",
    "                    ),\n",
    "                )\n",
    "                \n",
    "        except:\n",
    "            rr.log(\n",
    "                    \"camera/image\",\n",
    "                    rr.Pinhole(\n",
    "                        resolution=[camera.width, camera.height],\n",
    "                        focal_length=[camera.params[0], camera.params[0]],\n",
    "                    ),\n",
    "            )\n",
    "        \n",
    "        if resize:\n",
    "            bgr = cv2.imread(str(image_file))\n",
    "            bgr = cv2.resize(bgr, resize)\n",
    "            rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "            rr.log(\"camera/image\", rr.Image(rgb).compress(jpeg_quality=75))\n",
    "        else:\n",
    "            rr.log(\"camera/image\", rr.ImageEncoded(path=img_path / image.name.replace('.jpg', '.png')))\n",
    "        rr.log(\"camera/image/keypoints\", rr.Points2D(visible_xys, colors=[34, 138, 167]))\n",
    "          \n",
    "                     \n",
    "    print (\"Now preparing visualization engine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5f383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whatever you want to visualize in notebook, you should start the rec = rr.memory_recording()\n",
    "rec = rr.memory_recording()\n",
    "# rec = rr.notebook_show()\n",
    "read_and_log_sparse_reconstruction(Path(smf_path), Path(imgs_path), filter_output=False, resize=None)\n",
    "# And after it finishes - show it by just calling it  rec\n",
    "rr.notebook_show()\n",
    "# rr.start_web_viewer_server()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
